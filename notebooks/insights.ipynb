{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and initial insights on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': '0704.0001',\n",
       "  'submitter': 'Pavel Nadolsky',\n",
       "  'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
       "  'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies',\n",
       "  'comments': '37 pages, 15 figures; published version',\n",
       "  'journal-ref': 'Phys.Rev.D76:013009,2007',\n",
       "  'doi': '10.1103/PhysRevD.76.013009',\n",
       "  'report-no': 'ANL-HEP-PR-07-12',\n",
       "  'categories': 'hep-ph',\n",
       "  'license': None,\n",
       "  'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n',\n",
       "  'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'},\n",
       "   {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}],\n",
       "  'update_date': '2008-11-26',\n",
       "  'authors_parsed': [['Bal√°zs', 'C.', ''],\n",
       "   ['Berger', 'E. L.', ''],\n",
       "   ['Nadolsky', 'P. M.', ''],\n",
       "   ['Yuan', 'C. -P.', '']]},)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = db.read_text('../data/arxiv-metadata-oai.json').map(json.loads)\n",
    "\n",
    "# Take a look at the first record to see what we're working with\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of records\n",
    "num_records = dataset.count().compute()\n",
    "print(f\"Number of records: {num_records}\")\n",
    "\n",
    "# Sample record to understand attributes and their data types\n",
    "sample_record = dataset.take(1)[0]\n",
    "attributes = list(sample_record.keys())\n",
    "print(f\"Attributes in the dataset: {attributes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top authors\n",
    "top_authors = dataset.pluck(\"authors\").frequencies(sort=True).take(10)\n",
    "print(f\"Top 10 authors: {top_authors}\")\n",
    "\n",
    "# Number of unique titles (to check for duplicates)\n",
    "unique_titles_count = dataset.pluck(\"title\").distinct().count().compute()\n",
    "print(f\"Number of unique titles: {unique_titles_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# 1. Distribution of Categories\n",
    "category_counts = dataset.pluck(\"categories\").frequencies(sort=True).compute()\n",
    "categories, counts = zip(*category_counts[:15])  # Considering top 15 for clarity\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.barplot(x=list(categories), y=list(counts))\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 15 Categories by Number of Papers\")\n",
    "plt.ylabel(\"Number of Papers\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample approximately 10% of abstracts\n",
    "sample_abstracts = dataset.filter(lambda x: random.random() < 0.1).pluck(\"abstract\").compute()\n",
    "text = ' '.join(sample_abstracts)\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud for Abstracts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time span of the dataset\n",
    "dates = dataset.pluck('update_date').compute()\n",
    "min_date, max_date = min(dates), max(dates)\n",
    "print(f\"Time span of the dataset: {min_date} to {max_date}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
